Q： http2多路复用是怎么回事
A： 在一个 TCP 连接里，可以同时发送多个请求和响应，互不阻塞。
HTTP/1.1
单个 TCP 连接一次只能发送一个请求
超过浏览器并发限制会排队
会出现 队头阻塞（Head-of-line blocking）

单连接可以携带多个 Stream（流）
每个流独立传输
响应可以交错返回，不会因为一个大文件阻塞其它请求

HTTP/2 多路复用解决的问题

减少连接数
以前每个域名浏览器最多开 6~8 个 TCP 连接
HTTP/2 可以只用 1 个 TCP 连接就发送多请求

解决队头阻塞
HTTP/1.1 如果第一个请求慢，后面请求必须等待
HTTP/2 可以同时传输多个响应，慢的不会阻塞快的

提升网络利用率
数据交错传输
减少 TCP 握手和 TLS 开销
很多人误以为 HTTP/2 就能解决所有“图片同时加载卡顿”问题，其实不是。

主线程瓶颈
图片解码、JS 回调、布局绘制仍在主线程
网络快 ≠ 页面不卡

优先级控制有限
HTTP/2 支持流优先级，但浏览器对优先级支持有限
并不能保证 可视区或首屏图片优先加载

并发不是无限
虽然连接只有一个，但每个流也有最大数量
浏览器内部仍然可能排队


Q： 实现搜索页面图片资源并发调度与可视区加载优化”，先用 1 分钟讲一下你做了什么，解决了什么问题。
A： 这个优化主要针对搜索结果页图片密集、滚动快的场景。
我发现浏览器默认的图片加载在首屏优先级、并发控制上不可控，
快速滚动时会产生大量无效请求和解码开销。
所以我做了两件事：
1️⃣ 用 IntersectionObserver 控制图片进入或接近可视区时才触发加载
2️⃣ 在业务层设计图片加载任务队列，限制并发并支持优先级
最终减少了首屏白屏和快速滚动时的卡顿问题。

Q: 你这个“图片资源并发调度 + 可视区加载优化”是一个什么场景？为什么要做？
A: 在搜索结果页中，图片数量非常多，用户滚动速度快，如果直接让浏览器自由加载，会出现三个问题：
1️⃣ 首屏图片不能保证优先加载
2️⃣ 并发请求过多导致主线程、网络拥塞
3️⃣ 快速滚动时大量图片被请求但根本不会被看到

浏览器本身有并发限制，但它是域名级、无业务语义的。
在搜索页中，所有图片来自同一个 CDN，
浏览器无法保证可视区图片优先。
所以我在业务层维护一个任务队列，
控制最大并发，并让可视区图片优先执行

资源调度层：限制图片并发数，支持优先级
加载时机层：只在图片进入或接近可视区时才触发加载

Q：那你并发控制是怎么实现的？别跟我说“Promise.all”。
A： 我维护 activeCount 和一个等待队列：
当前并发小于阈值直接执行
超出则入队
每个任务完成后触发下一个
同时支持取消未执行任务，避免无效请求。

Q: 浏览器本身就有并发限制，你为什么还要自己做调度？
A: 浏览器的并发限制是基于域名级别的，而且是不可控的。
我这里的问题是：
搜索页图片全部来自同一个 CDN
快速滚动时会同时触发几十个图片加载
浏览器会排队，但无法保证“可视区图片优先”，
所以我在业务层实现了一个图片任务队列：
限制最大并发（比如 4）
可视区图片任务优先级更高
滚出视区的任务可以取消

浏览器并发限制是域名级别的，
但我需要的是：
可视区图片优先
非可视区图片延后甚至取消
浏览器无法感知“业务优先级”，
所以我在业务层维护了一个图片任务队列，
主动控制并发数和调度顺序

Q: 你是怎么实现这个并发调度的？
A: 我封装了一个 ImageLoader：
内部维护一个 任务队列 + activeCount
超过并发上限的任务进入队列
每个任务完成后，从队列中取下一个执行
对外暴露 load(url, priority)和cancel

Q: 你怎么判断图片进入可视区的？scroll 事件吗？
A: 我没有用 scroll 监听，而是使用 IntersectionObserver：
避免高频 scroll 回调
浏览器层面做可见性计算，性能更好
并且我设置了 rootMargin，
在图片即将进入可视区前就提前加载，避免用户看到空白。

Q: rootMargin 为什么要用？怎么设置？
A: 搜索页滚动速度快，如果等真正进入可视区才加载，会有明显白屏
所以我一般会：rootMargin: '200px 0px'
这样可以提前加载即将出现的图片，
同时又不会像一次性全加载那样浪费带宽。

Q: 如果用户快速滚动，已经发起的图片请求怎么办？
A: 逻辑层取消
图片任务还在队列中：直接丢弃
请求层取消（可选）
或 Image 对象直接丢弃引用，避免解码和回调

Q: 你有没有做过弱网或异常处理？
A: 单张图片设置超时，超时直接降级为占位图
加载失败后不重试，避免雪崩
在弱网下动态降低并发数

Q: 这个方案相比直接用 <img loading="lazy"> 有什么优势？
A: loading="lazy"：
无法控制并发
无法设置优先级
在复杂滚动容器下行为不稳定

业务可控
首屏优先
更适合搜索、瀑布流、Feed 场景

Q: IntersectionObserver 你是怎么用的？为什么不用 scroll？
A: scroll 事件频繁触发，需要手动节流，
IntersectionObserver 是浏览器原生的可见性检测，
性能更稳定，也更适合图片这种“是否进入视口”的场景。
我还配合 rootMargin，在图片即将进入可视区前就提前加载

Q: rootMargin 乱设会有什么问题？
A: rootMargin 设太大，本质就变成提前加载过多图片，
会导致：
首屏和非首屏资源竞争
带宽浪费

Q: 如果用户快速滚动，图片任务已经发出但马上滚出可视区，怎么办？
A: 任务还在队列中
直接移除，不发请求

请求已经发出
如果是 fetch：用 AbortController 取消
如果是 Image 对象：丢弃引用，避免后续解码和回调


Q: Image 对象丢弃引用真的有用吗？
A: 有用。
即使网络请求已经完成，只要没有引用：
不会触发 onload
不会参与后续布局
GC 后资源可回收

Q: 并发数你为什么选 4～6？拍脑袋吗？
A: 我一般会：
默认 4
首屏阶段可临时提升
弱网下降级到 2

Q: 如果让你再优化一步，你会怎么做？
A: 结合虚拟列表，减少 DOM + 图片同时存在数量
服务端返回图片尺寸，避免 CLS

Q: 你这个图片调度系统，本质解决的是「网络瓶颈」还是「渲染瓶颈」？
A: 两者都有，但优先解决的是渲染瓶颈。
在搜索页这种场景：
网络慢 ≠ 页面卡
真正导致掉帧的是 图片解码 + 布局 + 重绘
所以：
并发控制同时减少解码数量
可视区加载同时减少在 DOM 中的图片数量
网络只是表象，渲染才是根因。

Q: 既然虚拟列表能减少 DOM，为什么还要你这套图片调度？
A: 虚拟列表解决的是 DOM 数量，
但它并不控制：
图片请求时机
图片并发
图片解码顺序
如果虚拟列表窗口一次渲染 20 条，
这 20 张图片仍然可能同时解码，造成主线程抖动

虚拟列表控制 DOM + 图片调度控制资源


Q: 用户疯狂来回滚动，你的系统会不会抖动？
A: 不会出现资源雪崩，但可能出现调度抖动。
所以我做了：
已加载图片缓存（URL → blob / 状态）
滚出视口不立刻释放，保留短时间窗口

Q: 说一个你这套方案的缺点。
A: 实现复杂度高，调试成本比原生 lazyload 大。
不适合图片数量少、页面结构简单的场景。

Q: 图片加载主要是 I/O，你为什么老提主线程？
A: 图片请求是 I/O，
但解码、尺寸计算、布局、绘制都发生在主线程。
当大量图片同时 onload：
JS 回调
样式计算
Layout
会集中触发，导致掉帧。
并发调度的目的之一，就是错峰解码。

Q: 如果让你设计一套「通用图片加载 SDK」，你会怎么拆模块？
A: Observer 层
负责“是否进入可视区”

Scheduler 层
并发控制
优先级调度

Fetcher 层
Image / fetch
AbortController

Cache 层
已加载状态
blob / memory 策略

Q: 你这个优化最终带来了什么可量化的收益？
A: 在搜索页中：
首屏图片优先加载
快速滚动下无效图片请求减少40%+
页面掉帧明显减少，FPS 稳定性提升

Q：浏览器是怎么做并发调度的？
A：核心规则：按「域名」限制
并发限制是 per-origin（协议 + 域名 + 端口）
HTTP/1.1：≈ 6 个并发

HTTP/2：
表面无限
实际受 流、优先级、服务器配置限制

浏览器调度是「无业务语义」的
浏览器只知道：
URL
域名
连接状态
它不知道：
哪张图片在首屏
哪张用户马上要看到
哪个请求更重要

所以它的调度是：
公平但愚蠢的
这正是你要自己做并发调度的原因

Q： HTTP/2 不是多路复用吗？为什么还要控制并发？
A： HTTP/2 解决的是连接层的队头阻塞，
但并没有解决：
图片解码并发
JS 回调集中触发
主线程渲染压力
所以即使是 HTTP/2，
在图片密集页仍然需要业务层并发控制

Q： fetch 和 Image 的并发限制一样吗？
A： 是的，它们都受浏览器的 per-origin 并发限制。
差异在于：
fetch 可以中断（AbortController）
Image 更适合图片解码和缓存复用

Q： 我开 10 个 CDN 域名是不是就能绕过并发限制？
A： 技术上可以，但不推荐：
增加 DNS、TLS 成本
HTTP/2 场景收益很小
运维和缓存复杂度上升
更合理的是：
单域名 + 业务层调度


Q： 什么情况下「图片调度是必须的？

A： 图片调度不是“为了优化而优化”，
而是在图片成为核心信息、且浏览器默认调度无法满足用户体验时，
才引入的一层业务级控制

无限滚动 / 瀑布流搜索
移动端搜索页（关键加分点） （CPU 解码能力弱 网络波动大 滚动惯性强）
在移动端我会更加严格限制图片并发，
并优先保证首屏可见图片加载。

判断标准 1：单屏图片数量 ≥ 8
一屏 8 张以上，
同时解码就可能卡

判断标准 2： 图片体积不稳定
商品图
用户上传图 

判断标准 3：滚动速度快于加载速度
用户已经滚过去了，图片才开始加载

判断标准 4：同一 CDN 域名
浏览器并发队列失控


Q： 浏览器已经有 lazyload、IntersectionObserver、HTTP/2，你这套图片调度是不是过度设计？
A：我并不是替代浏览器能力，而是补浏览器做不到的部分。
浏览器 lazyload 只能决定是否加载，不能控制：
并发数量 优先级 取消策略
在图片是核心信息、并且存在快速滚动的搜索页中，
浏览器默认调度会明显影响首屏和滚动体验，
这时才有必要引入业务层调度

Q： IntersectionObserver + 调度 + 取消，你这套方案成本不低吧？真的值吗
A： 我有明确使用边界：
单屏图片数量低
分页式搜索
图片非核心信息
这些场景我不会用这套方案。
只有在图片密度高、滚动快、用户决策依赖图片的搜索页，
才会使用完整调度方案，否则优先用浏览器原生能力

Q： 图片请求已经发出，你取消它意义有多大？
A： 取消请求的核心收益不是流量，而是避免后续开销。
即使请求已经返回：
图片解码
onload 回调
样式和布局
仍然会消耗主线程。
取消或丢弃引用可以避免这些后续成本，
尤其是在快速滚动场景下

Q： 图片慢，不就是网络慢吗？跟你这套调度关系大吗？
A： 网络慢不一定卡，
页面卡往往是解码和渲染集中触发。
在图片密集搜索页中，
多张图片同时 onload 会触发布局和绘制，
这才是掉帧的主要原因。
并发调度的目标之一，就是错峰解码和渲染

Q： HTTP/2 不是多路复用吗？你这套并发限制是不是反而拖慢加载？
A： HTTP/2 解决的是连接层队头阻塞，
但浏览器仍然需要：
解码图片
执行回调
参与布局
在高密度图片页，
限制并发反而可以减少主线程抖动，
提升整体可见性体验，而不是单张图片最快加载

Q：你怎么证明这套方案真的有效？
A： 我主要看三类指标：
首屏图片可见时间
快速滚动下的无效请求比例
滚动时 FPS 稳定性
优化前后对比可以明显看到首屏和滚动体验改善

Q：你为什么不直接用虚拟列表解决？
A：虚拟列表解决的是 DOM 数量，
但并不控制图片请求和解码。
最优方案通常是：
虚拟列表减少 DOM
图片调度控制资源和渲染节奏
两者配合使用，而不是互相替代。

